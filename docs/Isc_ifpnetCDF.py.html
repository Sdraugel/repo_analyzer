
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>ifpnetCDF.py Details</title>
            <style>
                .container {
                    width: 60%;
                    margin: 50px auto;
                }
                h2 {
                    text-align: center;
                }
                .description {
                    background-color: #f9f9f9;
                    padding: 20px;
                    border: 1px solid #ddd;
                    border-radius: 5px;
                    margin-top: 20px;
                }
                button {
                    padding: 10px 20px;
                    background-color: #4CAF50;
                    color: white;
                    border: none;
                    cursor: pointer;
                }
                button:hover {
                    background-color: #45a049;
                }
            </style>
        </head>
        <body>
            <div class="container">
                <h2>ifpnetCDF.py</h2>
                <div class="description">
                    <p><strong>Description:</strong></p>
                    <p>This code file appears to be a part of a larger software system developed by Raytheon Company under a contract with the US Government. It contains export-restricted data, and its dissemination to non-U.S. persons requires an export license or other authorization.

The code file includes a detailed software history, documenting changes made to the code over time, including the date of the change, the ticket number related to the change, the engineer who made the change, and a description of the change.

The code itself is written in Python and imports several libraries such as calendar, collections, gzip, itertools, logging, os, shutil, stat, time, traceback, netCDF4, numpy, and JUtil. It also imports several modules from the com.raytheon.edex.plugin.gfe.server, com.raytheon.edex.plugin.gfe.smartinit, com.raytheon.uf.common.dataplugin.gfe.config, com.raytheon.uf.common.dataplugin.gfe.db.objects, com.raytheon.uf.common.localization, and iscUtil packages.

The code defines several constants and initializes a logger for logging events, problems, exceptions, and verbose logs. It also defines functions for logging these different types of logs. The logger is named "ifpnetCDF" and is set to log at the INFO level by default. The log messages are formatted by the iscUtil.tupleToString function.

It's worth noting that the code file is described as a "base file that is not intended to be overridden", suggesting that it provides some foundational functionality for the larger software system.

This code is written in Python and appears to be part of a larger system for handling and processing grid-based data, possibly related to weather or geographical information. Here's a breakdown of what each function does:

1. `logDebug(*msg)`: This function logs verbose debug messages.

2. `retrieveData(we, inv, clipArea)`: This function retrieves data from a grid system. It first determines the type of grid data (scalar, vector, weather, or discrete). It then creates an empty data cube of the appropriate type and size. It retrieves and encodes grids in batches, logging the time taken for each operation. If the number of grids retrieved is less than expected, it handles the discrepancy and logs the time taken to resolve it. The function returns the data cube, a dictionary of grid histories, and a list of keys.

3. `encodeGridSlice(grid, gridType, clipArea, cube, idx, keyList)`: This function encodes a slice of the grid into the data cube, depending on the grid type. For vector grids, it separately handles the magnitude and direction components. For weather or discrete grids, it also updates the key list.

4. `encodeGridHistory(histories)`: This function encodes the history of grid changes into a tuple of coded strings.

5. `processParmList(argDict, db)`: This function processes a list of parameters. If the list is empty, it retrieves all parameters from the database. It also ensures that all parameter names have the suffix "_SFC". It then verifies that each parameter is in the database, and returns the final list of parameters.

6. `contains(timerange, time)`: This function checks if a given time is within a specified time range.

7. `intersection(tr1, tr2)`: This function calculates the intersection of two time ranges. If there is no intersection, it returns None. The function is incomplete as it ends abruptly.

The code uses various libraries such as numpy for numerical operations, time for performance measurement, and OrderedDict for maintaining a dictionary in insertion order. It also uses some custom utilities like `iscUtil` and `JUtil`.

This code file seems to be a collection of utility functions related to time and spatial data manipulation. Here's a brief description of each function:

1. `overlaps(tr1, tr2)`: This function checks if two time ranges overlap. It returns 1 if they do and 0 if they don't.

2. `getIntTime(timeStr)`: This function converts a time string in the format "YYYYMMDD_HHMM" into an integer representing the time in seconds since 1-Jan-1970 00Z.

3. `makeTimeRange(startString, endString)`: This function creates a time range from two time strings.

4. `timeRangeAsString(tr)`: This function converts a time range into a string in the format "YYYYMMDD_HHMM".

5. `extremaOfSetBits(mask)`: This function returns the minimum and maximum x and y coordinates of non-zero elements in a 2D numpy array (mask).

6. `clipToExtrema(grid, clipArea)`: This function clips a 2D grid (numpy array) to the specified area.

7. `getDims(cdfFile, dimSizes, dimNames)`: This function returns a list of dimension names based on the tuple of integer sizes and the names of the dimensions. It also adds the dimension to the netCDF file, if necessary.

8. `getMaskGrid(ifpServer, editAreaName, dbId)`: This function creates a mask with all bits set for a specified edit area.

9. `storeLatLonGrids(ifpServer, cdfFile, krunch, clipArea)`: This function gets the grid location and projection information, clips the latitude and longitude grids to the specified area, and stores them in a netCDF file.

The code also handles exceptions and logs problems when they occur. It uses libraries like `time`, `calendar`, `numpy`, and `netCDF` for various operations.

The provided code is written in Python and appears to be part of a larger system for handling and storing grid-based data, such as geographical or meteorological data, in a NetCDF file format. NetCDF (Network Common Data Form) is a set of software libraries and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.

1. The `storeLatLonGrids()` function seems to be storing latitude and longitude grids in a NetCDF file. It first sets up a number of attributes such as the grid size, domain origin, domain extent, units, and projection attributes. It then creates a variable for longitude and stores the longitude grid in it. The function also logs the time taken for certain operations.

2. The `storeTopoGrid()` function is storing topographical grid data in the NetCDF file. It retrieves the topographical data, clips it to a specific area, and resizes it. It then creates a new variable in the NetCDF file and stores the topographical data in it. Similar to the previous function, it sets up a number of attributes and logs the time taken for certain operations.

3. The `storeGridDataHistory()` function appears to be storing the history of each grid in the NetCDF file. It calculates the maximum size of the history string, creates a history variable, and fills it with the history data.

4. The `calcKrunchValues()` function seems to be calculating values based on the weather element. It calculates the number of entries, checks for byte possibilities, and sets up a multiplier and offset. However, the code snippet provided is incomplete, so the full functionality of this function is not clear.

The provided code is written in Python and it appears to be part of a larger system that deals with weather data, possibly for a meteorological application. Here's a breakdown of what each part does:

1. The first part of the code is a function that determines the data type and related parameters based on the number of entries (`nentries`). It seems to be setting up different scenarios for handling data of different sizes, with specific conditions for when `nentries` is less than or equal to 127, less than or equal to 2^16 - 2, and any other case. It returns a tuple containing the data type, multiplier, offset, missing value, and Python type.

2. The `getProjectionAttributes` function retrieves attributes related to the projection of geographical data. It seems to handle different types of projections, including Lambert Conformal, Polar Stereographic, and Mercator. It returns a dictionary of these attributes.

3. The `storeWEAttributes` function stores attributes in a netCDF file for any weather element. It handles a variety of attributes including time ranges, grid size, domain origin and extent, min/max allowable values, data type, database ID, units, level, time constraints, precision, rate parm, and projection info. It also logs the time taken to calculate projection attributes and to call the `setncatts` method.

4. The `findOverlappingTimes` function seems to find time ranges that overlap with a specified time range from a list of time ranges. It returns an ordered dictionary of these overlapping time ranges.

5. The `storeScalarWE` function appears to store a weather element to a netCDF file. However, the code for this function is incomplete, so it's hard to determine exactly what it does.

The provided Python code is part of a larger program that deals with the storage and manipulation of weather data. It contains two main functions: `storeScalarWE()` and `storeVectorWE()`. Both functions are designed to store weather elements (WE) in a netCDF file, a format commonly used for storing multi-dimensional scientific data.

1. `storeScalarWE()`: This function stores scalar weather elements in the netCDF file. It first calculates overlapping times and retrieves the corresponding data. If the weather element is a rate parameter, it adjusts the data cube based on the duration ratio. The function then checks if any grids were found and gets the dimension list. It rounds the values according to the precision and masks the data. Finally, it creates a variable in the netCDF file and stores the weather element attributes, inventory, and grid history.

2. `storeVectorWE()`: This function is similar to `storeScalarWE()`, but it is designed to handle vector weather elements. It also calculates overlapping times, retrieves data, and adjusts the data cube if the weather element is a rate parameter. However, it deals with both magnitude and direction cubes. It rounds the values according to the precision, and if necessary, it adjusts the direction to fall within the range of 0 to 360 degrees.

Both functions use performance counters to measure the time taken for certain operations, which can be useful for performance debugging. They also log various events and information for debugging purposes.

The provided code is written in Python and appears to be part of a larger program that handles weather data. It contains several functions that perform various operations on this data.

1. The first function appears to be a part of a larger function (as indicated by the unexplained `at32)` at the start). This function is manipulating two 3D arrays (or "cubes") of data, `magCube` and `dirCube`, by setting certain values in these cubes to `mfillValue` and `dfillValue` respectively. It then creates two variables in a netCDF file (a type of file used to store multi-dimensional scientific data), one for each cube. The function also sets various attributes for these variables, such as a descriptive name, fill value, data multiplier, and data offset. It then stores these variables and their attributes in the netCDF file, and logs the time taken for these operations. Finally, it saves the grids to the netCDF file and logs the time taken for this operation as well.

2. The `collapseKey` function is used to update a grid and its keys. It creates a list of unique indexes in the grid, makes a reverse map, and modifies the data in the grid based on this map.

3. The `storeWeatherWE` function stores a weather element in a netCDF file. It first finds the overlapping times for a given time range, retrieves the data for these times, and creates a variable in the netCDF file to store this data. It then processes the weather keys to store only what is necessary, masks the values in the data cube, and saves the grids to the netCDF file. It also logs the time taken for these operations. Finally, it creates a new variable in the netCDF file to hold the weather keys. 

Overall, these functions seem to be part of a larger system for processing, storing, and retrieving weather data.

The provided code appears to be part of a larger Python script that deals with weather data. It includes several functions that perform various operations on this data, including storing it, retrieving it, and processing it. Here's a brief description of each function:

1. `storeWeatherWE()`: This function stores the weather element (WE) in a netCDF file. It first retrieves the data and stores it in a Numeric array. It then checks if any grids were found. If grids are found, it stores the attributes, processes the discrete keys, masks the values, and saves the grids to the netCDF file. It also logs the time taken for each operation.

2. `storeDiscreteWE()`: This function is similar to `storeWeatherWE()`, but it's specifically for storing discrete weather elements. It also finds overlapping times, retrieves data, checks for grids, stores attributes, processes keys, masks values, and saves grids to a netCDF file. It also logs the time taken for each operation.

3. `storeGlobalAtts()`: This function stores some global attributes to the netCDF file. These attributes include the creation time, file format version, start and end processing time.

4. `compressFile()`: This function compresses the netCDF file using the gzip library. The compression factor can be adjusted between 1 and 9, with 1 being the least compression and 9 being the most.

5. `getSamplingDefinition()`: This function retrieves the sampling definition from a server. It seems to be part of a larger system that involves user and site IDs, and it uses a path manager to handle file paths.

Please note that the code is incomplete and some functions are not fully defined in the provided snippet.

This code is written in Python and appears to be part of a larger program related to file and data management, specifically for a netCDF file. netCDF (Network Common Data Form) is a set of software libraries and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data.

Here's a breakdown of what the code does:

1. The first part of the code is trying to find a file specified by the `fileName` in different contexts. It first tries to find the file in the context set by the `userId`. If the file is not found and the `userId` is not 'BASE', it tries to find the file in the context for the site specified by `siteId`. If the file is still not found, it tries to find the file in the base context. If the file is not found in any of these contexts, it logs a problem and returns None.

2. If the file is found, it tries to open the file and execute its contents in a new namespace. It then returns the 'SampleDef' from the namespace. If there's an error during this process, it logs the problem and returns None.

3. The `determineSamplingValues` function takes in a sampling definition, a parameter name, an inventory, and a current time. It processes these inputs to determine the inventory of time ranges to include in the netCDF file. It handles cases where the sampling definition is None or the inventory is empty.

4. The `main` function initializes a logger, logs the start of the program, processes the command-line arguments, and sets up the IFP server. It then creates a time range from the start and end times, validates the database ID, processes the parameter list, determines the mask grid, and calculates the original and clipped grid sizes and the valid point count.

Overall, this code seems to be part of a larger system that manages and processes scientific data, likely in the context of meteorology or climatology given the references to grids, sampling definitions, and time ranges.

This Python script appears to be a part of a larger program that processes and stores grid data, possibly for geospatial or meteorological purposes. Here's a high-level overview of what this script does:

1. It inverts a mask grid using the `numpy.logical_not` function.

2. It retrieves a site ID from a database using the provided database ID, and gets a sampling definition based on the site ID, config file name, and user ID.

3. It opens a netCDF file (a format used to store array-oriented scientific data) for writing. If the file cannot be opened, it logs the exception and ends the program.

4. It loops over a list of parameters (`parmList`). For each parameter, it retrieves an item from the database, gets its keys, and determines the sampling values. It then checks the grid type of the item and stores it in the netCDF file accordingly. If any of these operations fail, it logs the exception and sets a flag (`partial_complete`) to True.

5. If the `geoInfo` argument is present, it stores the topographic grid and latitude/longitude grids in the netCDF file.

6. It stores global attributes in the netCDF file.

7. If the `partial_complete` flag is True (indicating that some operations failed), it deletes the output file and returns -1.

8. It calculates and logs various statistics about the grid data, such as the original and clipped grid sizes, the number of valid points, the total number of grids, and the percentage of clipped and valid points.

9. If the `compressFile` argument is True, it compresses the output file using gzip and calculates and logs the compression percentage and the number of bits per point before and after compression.

10. Finally, it logs the total elapsed and CPU time for the process.

The commented-out code at the end suggests that this script could be run as a standalone program (if the `if __name__ == "__main__":` line is uncommented), and that it could be profiled for performance analysis (if the rest of the commented-out code is uncommented).</p>
                </div>
                <div style="text-align: center; margin-top: 20px;">
                    <a href="javascript:history.back()"><button>Back</button></a>
                </div>
            </div>
        </body>
        </html>
        